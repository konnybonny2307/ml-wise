{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width='100%'>\n",
    "<tr>\n",
    "<td style='background-color:white'>\n",
    "    <p align=\"left\">\n",
    "    Exercises for the course<br>\n",
    "        <b>Machine Learning for Data Science</b><br>\n",
    "    Winter Semester 2024/25\n",
    "    </p>\n",
    "</td>\n",
    "<td style='background-color:white'>\n",
    "    G. Montavon<br>\n",
    "    Institute of Computer Science<br>\n",
    "    <b>Department of Mathematics and Computer Science</b><br>\n",
    "    Freie Universit√§t Berlin\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <h1>Exercise Sheet 1</h1>\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "In the following, we explore different ways of accessing data, including reading CSV files, querying databases, and applying preprocessing and plotting techniques to the available data. The cell below imports some libraries that are required to complete the tasks. Note that you need to install additional python libraries such as `cv2`, `torch`, `torchvision`, `matolotlib` and `sqlite3`. Some of these libraries will also be needed for the next exercise sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy,scipy,scipy.spatial\n",
    "import torch\n",
    "import torchvision,torchvision.transforms\n",
    "import sqlite3\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Loading CSV Data (15+15 P)\n",
    "\n",
    "In this exercise, we investigate the usage of the function `numpy.genfromtxt` to load several datasets from the UCI repository. These datasets are provided in the form of csv files in the folder `csvdata` of the homework.\n",
    "\n",
    "\n",
    "\n",
    "**(a)** Using the method `numpy.genfromtxt`, load the dataset contained in the file `Wholesale customers data.csv`. In this dataset, instances (rows) are retailers, and features (columns) represent how much these retailers spend for different categories of products. Once the dataset is loaded, compute the average and median spending (over instances) for each category of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 8)\n",
      "[1.32272727e+00 2.54318182e+00 1.20002977e+04 5.79626591e+03\n",
      " 7.95127727e+03 3.07193182e+03 2.88149318e+03 1.52487045e+03]\n",
      "[1.0000e+00 3.0000e+00 8.5040e+03 3.6270e+03 4.7555e+03 1.5260e+03\n",
      " 8.1650e+02 9.6550e+02]\n"
     ]
    }
   ],
   "source": [
    "data = numpy.genfromtxt('csvdata/Wholesale customers data.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "arithmetic_mean = numpy.mean(data, axis=0)\n",
    "median = numpy.median(data, axis=0)\n",
    "\n",
    "print(data.shape)\n",
    "print(arithmetic_mean)\n",
    "print(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Using the method `numpy.genfromtxt`, load the dataset contained in the file `CortexNuclear.csv`, and use the library `matplotlib` to produce an image plot that visualizes the dataset, specifically visualize the first 30 instances that do not contain any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# TODO: Replace by your code\n",
    "# ------------------------------------\n",
    "import solutions\n",
    "solutions.task1b()\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Querying a Database (20+20 P)\n",
    "\n",
    "In the following, we will use the sqlite3 package to connect to a database, and perform various join operations. The sqlite3 package enables you to connect to a database and to perform various queries. We will consider the chinook database, which simulates data from a music store, relating music tracks, artists, invoices, customers, etc. Connect to the database. The database can also be downloaded from the link https://www.sqlitetutorial.net/sqlite-sample-database/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('chinook.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database has the following schema\n",
    "\n",
    "![](sqlite-sample-database-color.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first consider a simple query on this database. The query is formulated in the SQL language and retrieves the duration of tracks found in that database. Once the results of the query have been obtained, we perform a very basic data analysis: computing the mean track duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.cursor()\n",
    "query = \"SELECT Milliseconds FROM tracks;\"\n",
    "results = numpy.array(cursor.execute(query).fetchall())\n",
    "mean = results.mean()/1000.0\n",
    "print(f\"{'Average track duration':25s} {mean:8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would like to perform more complex SQL queries. For a tutorial on SQL, see for example, https://www.sqltutorial.org/. In particular, look at Section 6 which discusses the SQL operation \"INNER JOIN\" and that is useful for generating outputs involving multiple tables.\n",
    "\n",
    "**(a)** Apply a SQL query that extracts a table containing for all tracks their genre and their track length. Then, write code that computes for each genre (sorted alphabetically the average track length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# TODO: Replace by your code\n",
    "# ------------------------------------\n",
    "import solutions\n",
    "solutions.task2a(db)\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to analyze the preference for music genres in different countries.\n",
    "\n",
    "**(b)** Apply a SQL query that extracts for each invoice the country of the customer and the genre of the track the customer has purchased. Then, print in the form of a table the number of purchases for each country and genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# TODO: Replace by your code\n",
    "# ------------------------------------\n",
    "import solutions\n",
    "solutions.task2b(db)\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Representing Images (15+15 P)\n",
    "\n",
    "Images are high-dimensional data. High-level concepts contained in these images are hard to extract directly from the raw pixel representation. In the following, we investigate the benefit of preprocessing the data with a neural network. Specifically, we want to see if representations built by the neural network enable to produce meaningful similarities or dissimilarities between images. We consider for this exercise a set ot 10 images. The first 5 images depict geraniums, and the last 5 images depict ferrari cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [Image.open(f'imagedata/{i}.jpg') for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the two groups are clearly distinct from a human point of view, we will show that distances computed on pixel values (i.e. treating an image as vector storing the multiple RGB pixel values) does do not enable such distinction.\n",
    "\n",
    "**(a)** Compute a matrix of pairwise Euclidean distances between images (images are resized to 100 x 100 for this task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizedimages = [numpy.array(img.resize((100,100))).flatten() for img in images]\n",
    "\n",
    "# ------------------------------------\n",
    "# TODO: Replace by your code\n",
    "# ------------------------------------\n",
    "import solutions\n",
    "D = solutions.task3a(resizedimages)\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance matrix can then be displayed using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(D)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot see clear similarities (low distances) within each image group. This suggests that the pixel representation does not encode well the concepts we are interested in.\n",
    "\n",
    "To address this limitation, we consider a state-of-the-art neural network called `densenet161` and available pretrained in the `torchvision` libary. This neural network is composed of a feature extractor and a classification head. The feature extractor transforms image data (given as a `torch` tensor) into a tensor of activations where concepts are easier to predict.\n",
    "\n",
    "**(b)** Compute the distance matrix between the images represented at the output of the densenet features extractor.\n",
    "\n",
    "*Hints: (1) The input images need to be converted to a torch tensor and the normalized using the function provided below before being fed to the neural network. (2) Note that the tensor at the output of the network can vary in shape due to the varying size of the input images. This can be addressed by applying the mean operation over the two dimensions representing the horizontal and vertical components.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.densenet161(pretrained=True).features\n",
    "model.eval();\n",
    "\n",
    "def normalize(x):\n",
    "    x = x - torch.Tensor([0.485, 0.456, 0.406]).reshape(1,-1,1,1)\n",
    "    x = x / torch.Tensor([0.229, 0.224, 0.225]).reshape(1,-1,1,1)\n",
    "    return x\n",
    "\n",
    "# ------------------------------------\n",
    "# TODO: Replace by your code\n",
    "# ------------------------------------\n",
    "import solutions\n",
    "D = solutions.task3b(images,model,normalize)\n",
    "# ------------------------------------\n",
    "\n",
    "plt.imshow(D)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that distances now form a block structure, where the first 5 images are clearly mutually similar, and similarly for the last 5 images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
