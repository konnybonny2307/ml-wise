{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width='100%'>\n",
    "<tr>\n",
    "<td style='background-color:white'>\n",
    "    <p align=\"left\">\n",
    "    Exercises for the course<br>\n",
    "        <b>Machine Learning for Data Science</b><br>\n",
    "    Winter Semester 2024/25\n",
    "    </p>\n",
    "</td>\n",
    "<td style='background-color:white'>\n",
    "    G. Montavon<br>\n",
    "    Institute of Computer Science<br>\n",
    "    <b>Department of Mathematics and Computer Science</b><br>\n",
    "    Freie Universit√§t Berlin\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <h1>Exercise Sheet 5 (programming part)</h1>\n",
    "</center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import utils\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "import torchvision\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "lcm = matplotlib.colors.ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 (10 + 10 P)\n",
    "\n",
    "In this exercise we perform a clustering of the Iris dataset, which was also used in the previous two assignments.\n",
    "\n",
    "![](iris_measurements.png)\n",
    "\n",
    "The dataset associate to each plant instance four measurements. The dataset also includes for each instance the type of iris plant (iris setosa, iris versicolour, iris virginica) which we treat here as metadata. Overall, the Iris dataset has 150 instances, and can be stored as an array of size 150 x 4. The following cell loads the dataset and performs some normalization. We also generate a PCA representation of the data for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.load_iris()\n",
    "\n",
    "X = numpy.log(0.1+dataset['data'])\n",
    "T = dataset['target']\n",
    "\n",
    "Z = sklearn.decomposition.PCA(2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on one of the simplest clustering methods, which is to find the *connected components* of a graph associated to the dataset. We consider a graph where two nodes are connected if the distance between the corresponding instances (after dataset normalization) is below some threshold value `delta`.\n",
    "\n",
    "**(a)** Implement this simple clustering method. *(Hint: you can make use of the method `scipy.sparse.csgraph.connected_components` to find the connected components associated to a particular adjacency matrix.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedComponentsClustering:\n",
    "\n",
    "    def __init__(self,delta):\n",
    "        self.delta = delta \n",
    "        \n",
    "    def fit_predict(self,X):\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # TODO: Replace by your code\n",
    "        # ------------------------------------------\n",
    "        import solution\n",
    "        n_components, Y = solution.cc_fit_predict(self,X)\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        return n_components, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is now applied to the Iris dataset with a particular threshold value `delta = 0.5`. Results are visualized in a PCA plot, where instances are color-coded according to their cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.5\n",
    "\n",
    "n_components, Y = ConnectedComponentsClustering(delta).fit_predict(X)\n",
    "\n",
    "print(n_components)\n",
    "\n",
    "utils.preparefigure(1)\n",
    "plt.scatter(*Z.T,c=Y,cmap='tab10',vmin=0,vmax=10,alpha=0.5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe two clusters. Clusters are consistent with what a human can see in the PCA plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** We now would like to compare the taxonomy derived from the clustering above with the actual iris types available as meta-data. *Write* code that produces a correspondence table linking the clustering to the classification into iris types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = dataset['target']\n",
    "names = dataset['target_names']\n",
    "\n",
    "# ------------------------------------------\n",
    "# TODO: Replace by your code\n",
    "# ------------------------------------------\n",
    "import solution\n",
    "solution.correspondence(names,T,n_components,Y)\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a one-to-one correspondence bewteen cluster 0 and the type iris setosa. The two other iris types (versicolor and virginica) are grouped in the second cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 (10 + 10 + 10 P)\n",
    "\n",
    "In this exercise, we consider clustering of fashion items from the FashionMNIST dataset. The FashionMNIST dataset consists of 60000 fashion items, each of which coming as a 28 x 28 grayscale image. For the purpose of limiting computations, we consider a subset of 1000 instances from this dataset, and thus, extract a dataset of size 1000 x 784 (the 784 dimensions correspond to representing images as a flat vector). We also generate a PCA representation of the data for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torchvision.datasets.FashionMNIST('.',download=True).data.numpy()\n",
    "\n",
    "numpy.random.seed(0)\n",
    "R = numpy.random.permutation(len(X))[:1000]\n",
    "X = X[R].reshape(-1,784)\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "Z = sklearn.decomposition.PCA(n_components=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 50 images of our dataset are visualized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(X[:50].reshape(5,10,28,28).transpose(0,2,1,3).reshape(5*28,10*28),cmap='gray',vmin=0,vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Implement a rudimentary version of K-Means, where the cluster centers are initialized to the first few examples of the dataset, and where the number of iterations is fixed to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "\n",
    "class KMeans:\n",
    "    \n",
    "    def __init__(self,n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    def fit(self,X):\n",
    "\n",
    "        # ------------------------------------------\n",
    "        # TODO: Replace by your code\n",
    "        # ------------------------------------------\n",
    "        import solution\n",
    "        solution.kmeans_fit(self,X)\n",
    "        # ------------------------------------------\n",
    "\n",
    "    def predict(self,X):\n",
    "        \n",
    "        D = scipy.spatial.distance.cdist(X,self.cluster_centers_)\n",
    "        return numpy.argmin(D,axis=1)\n",
    "\n",
    "model = KMeans(20)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome of your clustering procedure can be visualized in the following PCA plot color-coded by cluster membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(0)\n",
    "Y = model.predict(X)\n",
    "\n",
    "utils.preparefigure(7)\n",
    "plt.scatter(*Z.T,c=Y,s=20,vmin=0,vmax=20,cmap='tab20',alpha=0.5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** We now would like to get insights into what are prototypical fashion items in our dataset. For this, we consider the cluster centers learned by k-means. *Extract* these cluster centers and *visualize* them as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# TODO: Replace by your code\n",
    "# ------------------------------------------\n",
    "import solution\n",
    "solution.view_cluster_centers(model)\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Lastly, we would like to know how well these cluster centers describe our data. Using the formulas presented in the lecture, compute the total variance, the within-cluster variance, the between-cluster variance, and the percentage of explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# TODO: Replace by your code\n",
    "# ------------------------------------------\n",
    "import solution\n",
    "solution.analyze_variance(X,model)\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that a bit more than half of the variance in the data is captured by the clustering, which is quite good, considering that the data is high-dimensional. Note that a higher explained variance could be obtained by incorporating more clusters, however that would come at the cost of making the data description potentially too complex for the end user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
